###This project uses R studio to scrap tweets from twiter related two vaccines fom two cities. Tweets were cleaned and scored by valence for sentimenet analysis. 
####Attitudes toward vaccines were compared between cities.


###Package installations 


install.packages("twitteR")
install.packages("ROAuth")
install.packages("RCurl")
install.packages("httr")

install.packages("stringr")
install.packages("plyr")
install.packages("dplyr")
install.packages("tm")

#install.packages("ggmap")
#install.packages("wordcloud")


#Active the installed packages: 

library(twitteR)
library(ROAuth)
library(RCurl)
library(httr)

library(stringr)
library(plyr)
library(dplyr)
library(tm)

#library(ggmap)
#library(wordcloud)

### Establishing A Connection - Direct Method

key="IAzPMDZeBFqTe8xUPK2lUR1wn"
secret="JMvql2WTj1O90HrdJ07j377r5bRknpZ9E7hgLmeD4Edbmc5AyM"

atoken =  "407881027-33sqeNuAHWb4YMoeT6WOeNhwdqBdE2wDunXW0Rxv"
asecret = "WRgJoWlQPdl5IcXWVnQd933goei9N59NvIVzZIszNYBIq"

setup_twitter_oauth(key, secret, atoken, asecret)




# scraping the tweets with searchTwitter with keyword "vaccine" within 500 miles of Los Angeles
tweets = searchTwitter("vaccine", n=1000, 
                       lang="en", 
                       geocode="34.1,-118.2,500mi",  since = "2021-10-15")


# extracting the text
tweettext = sapply(tweets, function(x) x$getText())
#extracting dates

tweetdate=lapply(tweets, function(x) x$getCreated())

tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))

tweetdate

##cleaning tweets

tweettext=lapply(tweettext, function(x) iconv(x, "latin1", 
                                              "ASCII", sub=""))
tweettext=lapply(tweettext, function(x) gsub("htt.*",' ',x))
tweettext=lapply(tweettext, function(x) gsub("#",'',x))
tweettext=unlist(tweettext)

# getting the opinion lexicons from working directory
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")

neg2 = c(neg, "bearish", "fraud"); tail(neg2)

## apply function score.sentiment


### Sentiment Score Function - approach after J. Breen

library("stringr")

library("plyr")

# Function is called sentimentfun
sentimentfun = function(tweettext, pos, neg, .progress='non')
{
  # Parameters
  # tweettext: vector of text to score
  # pos: vector of words of postive sentiment
  # neg: vector of words of negative sentiment
  # .progress: passed to laply() 4 control of progress bar
  
  # create simple array of scores with laply
  scores = laply(tweettext,
                 function(singletweet, pos, neg)
                 {
                   # remove punctuation - using global substitute
                   singletweet = gsub("[[:punct:]]", "", singletweet)
                   # remove control characters
                   singletweet = gsub("[[:cntrl:]]", "", singletweet)
                   # remove digits
                   singletweet = gsub("\\d+", "", singletweet)
                   
                   # define error handling function when trying tolower
                   tryTolower = function(x)
                   {
                     # create missing value
                     y = NA
                     # tryCatch error
                     try_error = tryCatch(tolower(x), error=function(e) e)
                     # if not an error
                     if (!inherits(try_error, "error"))
                       y = tolower(x)
                     # result
                     return(y)
                   }
                   # use tryTolower with sapply 
                   singletweet = sapply(singletweet, tryTolower)
                   
                   # split sentence into words with str_split (stringr package)
                   word.list = str_split(singletweet, "\\s+")
                   words = unlist(word.list)
                   
                   # compare words to the dictionaries of positive & negative terms
                   pos.matches = match(words, pos)
                   neg.matches = match(words, neg)
                   
                   # get the position of the matched term or NA
                   # we just want a TRUE/FALSE
                   pos.matches = !is.na(pos.matches)
                   neg.matches = !is.na(neg.matches)
                   
                   # final score
                   score = sum(pos.matches) - sum(neg.matches)
                   return(score)
                 }, pos, neg, .progress=.progress )
  
  # data frame with scores for each sentence
  sentiment.df = data.frame(text=tweettext, score=scores)
  return(sentiment.df)
}




scores = sentimentfun(tweettext, pos, neg, .progress='text')




## extracting further elements (besides text) for the export csv

tweetdate=lapply(tweets, function(x) x$getCreated())
tweetdate=sapply(tweetdate,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))

isretweet=sapply(tweets, function(x) x$getIsRetweet())

retweetcount=sapply(tweets, function(x) x$getRetweetCount())

favoritecount=sapply(tweets, function(x) x$getFavoriteCount())

## Creating the Data Frame
data=as.data.frame(cbind(ttext=tweettext,
                         date=tweetdate,
                         isretweet=isretweet, 
                         retweetcount=retweetcount,
                         favoritecount=favoritecount,
                         score = scores)
)

## label duplicates
data2 = duplicated(data[,1])

data$duplicate = data2

## create file to working directory 
write.csv(data, file= "data.csv")


##read data.csv into R 
tweet=read.csv("data.csv")
attach(tweet)
names(tweet)




Create worldcloud

install.packages("wordcloud")
library(wordcloud)

tweetcleandata=read.csv("data.csv")
names(data)
attach(data)

wordcloud(ttext, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))


tweettext

tweetdate

# extracting tweets with keyword "Vaccine" from miami
tweets2 = searchTwitter("vaccine", n=1000, 
                       lang="en", 
                       geocode="25.7,80.19,500mi",  since = "2021-10-15")


tweet2date

# extracting the text
tweet2text = sapply(tweets2, function(x) x$getText())
#extracting dates

tweet2date=lapply(tweets2, function(x) x$getCreated())

tweet2date=sapply(tweet2date,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))



##cleaning tweets

tweet2text=lapply(tweet2text, function(x) iconv(x, "latin1", 
                                              "ASCII", sub=""))
tweet2text=lapply(tweet2text, function(x) gsub("htt.*",' ',x))
tweet2text=lapply(tweet2text, function(x) gsub("#",'',x))
tweet2text=unlist(tweet2text)

tweet2text

# getting the opinion lexicons from working directory
pos = readLines("positive_words.txt")
neg = readLines("negative_words.txt")

neg2 = c(neg, "bearish", "fraud"); tail(neg2)

## apply function score.sentiment


### Sentiment Score Function - approach after J. Breen

library("stringr")

library("plyr")

# Function is called sentimentfun
sentimentfun = function(tweettext, pos, neg, .progress='non')
{
  # Parameters
  # tweettext: vector of text to score
  # pos: vector of words of postive sentiment
  # neg: vector of words of negative sentiment
  # .progress: passed to laply() 4 control of progress bar
  
  # create simple array of scores with laply
  scores = laply(tweettext,
                 function(singletweet, pos, neg)
                 {
                   # remove punctuation - using global substitute
                   singletweet = gsub("[[:punct:]]", "", singletweet)
                   # remove control characters
                   singletweet = gsub("[[:cntrl:]]", "", singletweet)
                   # remove digits
                   singletweet = gsub("\\d+", "", singletweet)
                   
                   # define error handling function when trying tolower
                   tryTolower = function(x)
                   {
                     # create missing value
                     y = NA
                     # tryCatch error
                     try_error = tryCatch(tolower(x), error=function(e) e)
                     # if not an error
                     if (!inherits(try_error, "error"))
                       y = tolower(x)
                     # result
                     return(y)
                   }
                   # use tryTolower with sapply 
                   singletweet = sapply(singletweet, tryTolower)
                   
                   # split sentence into words with str_split (stringr package)
                   word.list = str_split(singletweet, "\\s+")
                   words = unlist(word.list)
                   
                   # compare words to the dictionaries of positive & negative terms
                   pos.matches = match(words, pos)
                   neg.matches = match(words, neg)
                   
                   # get the position of the matched term or NA
                   # we just want a TRUE/FALSE
                   pos.matches = !is.na(pos.matches)
                   neg.matches = !is.na(neg.matches)
                   
                   # final score
                   score = sum(pos.matches) - sum(neg.matches)
                   return(score)
                 }, pos, neg, .progress=.progress )
  
  # data frame with scores for each sentence
  sentiment.df = data.frame(text=tweettext, score=scores)
  return(sentiment.df)
}




scores2 = sentimentfun(tweet2text, pos, neg, .progress='text')




## extracting further elements (besides text) for the export csv

tweetdate2=lapply(tweets2, function(x) x$getCreated())
tweetdate2=sapply(tweetdate2,function(x) strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC"))

isretweet2=sapply(tweets2, function(x) x$getIsRetweet())

retweetcount2=sapply(tweets2, function(x) x$getRetweetCount())

favoritecount2=sapply(tweets2, function(x) x$getFavoriteCount())

## Creating the Data Frame
data2=as.data.frame(cbind(ttext=tweet2text,
                         date=tweetdate2,
                         isretweet=isretweet2, 
                         retweetcount=retweetcount2,
                         favoritecount=favoritecount2,
                         score = scores2)
)

## label duplicates
datamiami = duplicated(data2[,1])

data2$duplicate = datamiami

## create file to working directory 
write.csv(data, file= "data.csv")


##read data.csv into R 
tweet=read.csv("data.csv")
attach(tweet)
names(tweet)




#Create worldcloud

install.packages("wordcloud")
library(wordcloud)

tweetcleandata=read.csv("data.csv")
names(data)
attach(data)

wordcloud(ttext, min.freq=5, scale=c(3.5, .5), random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))


data$location="los angeles"
data2$location="miami"

#Combine data
datafull=rbind(data,data2)

datafull


#create histograms
par(mfrow=c(1,2))
hist(datafull$score.score[datafull$location=="miami"],xlab="sentiment score",ylab="frequency", main = "Miami")
hist(datafull$score.score[datafull$location=="los angeles"],xlab="sentiment score",ylab="frequency", main = "Los Angeles")

tapply(datafull$score.score, datafull$location, FUN = summary)

#Mean comparison vaccine sentiment
t.test(score.score~location,data=datafull)
